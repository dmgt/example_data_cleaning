---
title: "Example of standardizing, summarizing, and plotting NOAA LCD weather data"
author: "Dana Miller"
output:
  github_document:
    toc: true
    toc_depth: 5
editor_options: 
  chunk_output_type: console
---

The examples below are exerpts from a scientific manuscript demonstrating common data manipulation and visualization taaks using the popular `tidyverse` and `ggplot2` packages in R. My goal is to provide an accesible introduction to this workflow for users new to RMarkdown documents, using publically avalible data. This is a simplified version of relevant steps when processing, summarizing, and presenting data in a research report or manuscript. 

```{r setup, message = F, warning = F, echo = T}
# Load required libraries
require(lubridate)  # note lubridate::here conflicts with here::here, specify namespace explicitly when used below
require(tidyverse)
require(here)       # package to manage relative file paths
require(skimr)
require(cowplot)    # package for additional plotting options
```

### Load data
```{r readDeviceData, eval = F, echo = F, cache = 2}
## Will use convention of `_cleaned` to designate data from `/cleaned_data`, but note that each dataset has substantial additional processing below, eg taking hourly averages, merging with metadata, aligning naming conventions between datasets etc
weather_cleaned <- read_rds(here::here("cleaned_data/allWeather.rds"))

```

### Load helper functions

```{r helperFunctions, eval = T}
# Function to remove data from dates during mechanical system failure at one site (unrepresentitive performance data)
filter_hvac_failure <- function(input_df) {
      site1_filtered <-  input_df %>%
                        filter(site == "Site1") %>% 
                        filter(datetime_utc_hourly < "2018-08-10" | datetime_utc_hourly > "2019-06-24")
      
      other_sites_filtered <-  input_df %>%
                              filter(site != "Site1") 
      
      compressors_field_study_filtered <- bind_rows(site1_filtered, other_sites_filtered) %>% 
                              arrange(datetime_utc_hourly)
      return(compressors_field_study_filtered )
    }
    
```

## Data standarization

### Notes for all datasets 

**Conventions as follows:**

-  `_hourly` : version of dataset with hourly averages
- `_info`: version of dataset with the following variables created:
    - intervention: 'Baseline' or 'Intervention' (based on dates of week fans started operating, in code below)
    - From zone_metadata file
        - hvac_zone_display: eg C1, C2...R1-R6 (C = Commercial, R = Residential)
        - space_occupancy_type: Residential, Commercial - irregular occupancy, Commercial - regular occupancy
    - From transformations of existing data
         - month (numeric) - for functions that filter by month
         - month_factor (factor) - for boxplots that need factor input
         - year (numeric) - for functions that filter by calender year
         - hour (numeric) - for functions that filter by hour of day ( 0 - 23)
         - hour_factor(factor) - for boxplots that need factor input
    - Only for weather file
        - site_display - To combine Site 3 + 4 as one factor for graphing since weather files are same (co-located sites)
- The cleaned file, with the info above appended, will be called `*_info`
- The file with info appended, and additionally summarized to hourly averages, will be named `*_hourly` (not `*_hourly_info`) for brevity, if it's hourly the 'info' has alreadly been appended :)
- Dataframes that have additionally been filtered to remove the HVAC failure period for data from Site 1 (ie dataframe has full timeperiod for site 2-4 data, and Site 1 data only putside of HVAC failure period) are labeled as 'filtered'

